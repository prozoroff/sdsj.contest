{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "We'll need to predict relevance between paragraph and question pair. \n",
    "In input we have some paragraphs, question and (for train set) paragraph-question relevance. Also, in test set we'll see some generated qquestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from functools import lru_cache\n",
    "from itertools import chain\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "from ipywidgets import IntProgress\n",
    "from gensim.models import Word2Vec\n",
    "from Levenshtein import distance\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1094</td>\n",
       "      <td>46273</td>\n",
       "      <td>В отличие от рыб, земноводные (амфибии) и прес...</td>\n",
       "      <td>С какого года Русское Царство перешло на летои...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7414</td>\n",
       "      <td>19164</td>\n",
       "      <td>В 1049 году Балдуину V удалось отнять у Герман...</td>\n",
       "      <td>Кто упомянул о его первых разногласиях со Штей...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6744</td>\n",
       "      <td>39767</td>\n",
       "      <td>Стремление достичь предельных значений ёмкости...</td>\n",
       "      <td>Как называется имеющая мировое значение эпоха ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7300</td>\n",
       "      <td>36318</td>\n",
       "      <td>Первый практически пригодный двухтактный газов...</td>\n",
       "      <td>Что усугублялось из-за международного давления...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7077</td>\n",
       "      <td>41534</td>\n",
       "      <td>Требуя от художника углубленного изучения изоб...</td>\n",
       "      <td>Какой характер носят пророчества Леонардо да В...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3559</td>\n",
       "      <td>62585</td>\n",
       "      <td>Белки — высокомолекулярные органические вещест...</td>\n",
       "      <td>Какие действия предприняла подводная лодка Чер...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4350</td>\n",
       "      <td>3730</td>\n",
       "      <td>Прайсинговые методы — в основе лежит принцип и...</td>\n",
       "      <td>Как называют остановки, до которых и на которы...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8012</td>\n",
       "      <td>86629</td>\n",
       "      <td>Применяли изначально для определения близкород...</td>\n",
       "      <td>Какой признак киевский монах Нестор-летописец ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3634</td>\n",
       "      <td>69421</td>\n",
       "      <td>Успешная конверсия по-разному определяется гру...</td>\n",
       "      <td>Чтобы понять, по какому рекламному каналу приш...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4350</td>\n",
       "      <td>27335</td>\n",
       "      <td>Прайсинговые методы — в основе лежит принцип и...</td>\n",
       "      <td>Урожайность сои в каких странах почти не отлич...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0          1094        46273   \n",
       "1          7414        19164   \n",
       "2          6744        39767   \n",
       "3          7300        36318   \n",
       "4          7077        41534   \n",
       "5          3559        62585   \n",
       "6          4350         3730   \n",
       "7          8012        86629   \n",
       "8          3634        69421   \n",
       "9          4350        27335   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  В отличие от рыб, земноводные (амфибии) и прес...   \n",
       "1  В 1049 году Балдуину V удалось отнять у Герман...   \n",
       "2  Стремление достичь предельных значений ёмкости...   \n",
       "3  Первый практически пригодный двухтактный газов...   \n",
       "4  Требуя от художника углубленного изучения изоб...   \n",
       "5  Белки — высокомолекулярные органические вещест...   \n",
       "6  Прайсинговые методы — в основе лежит принцип и...   \n",
       "7  Применяли изначально для определения близкород...   \n",
       "8  Успешная конверсия по-разному определяется гру...   \n",
       "9  Прайсинговые методы — в основе лежит принцип и...   \n",
       "\n",
       "                                            question  target  \n",
       "0  С какого года Русское Царство перешло на летои...     0.0  \n",
       "1  Кто упомянул о его первых разногласиях со Штей...     0.0  \n",
       "2  Как называется имеющая мировое значение эпоха ...     0.0  \n",
       "3  Что усугублялось из-за международного давления...     0.0  \n",
       "4  Какой характер носят пророчества Леонардо да В...     0.0  \n",
       "5  Какие действия предприняла подводная лодка Чер...     0.0  \n",
       "6  Как называют остановки, до которых и на которы...     0.0  \n",
       "7  Какой признак киевский монах Нестор-летописец ...     1.0  \n",
       "8  Чтобы понять, по какому рекламному каналу приш...     1.0  \n",
       "9  Урожайность сои в каких странах почти не отлич...     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain = pd.read_csv(\"train_task1_latest.csv\")\n",
    "dftrain.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1361</td>\n",
       "      <td>6463</td>\n",
       "      <td>Передний мозг сильно развит, это самая большая...</td>\n",
       "      <td>В какой мифологии два ворона Хугин и Мунин шеп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1403</td>\n",
       "      <td>34696</td>\n",
       "      <td>Мирмекологи исследуют муравьёв как в лаборатор...</td>\n",
       "      <td>Когда инсайдер покупает или гипотезы чего эвол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1435</td>\n",
       "      <td>13751</td>\n",
       "      <td>Волновая: свет представляет собой волну в неви...</td>\n",
       "      <td>Какие предположения, по мнению Ньютона, допуст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341</td>\n",
       "      <td>38544</td>\n",
       "      <td>Живые организмы подчиняются началам термодинам...</td>\n",
       "      <td>В каких условиях метаболизм поддерживает поряд...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1317</td>\n",
       "      <td>14589</td>\n",
       "      <td>Файлы нелатинского текста в Юникоде всегда зан...</td>\n",
       "      <td>Каким мелодиям Прокофьева особенно не укладыва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>412</td>\n",
       "      <td>26912</td>\n",
       "      <td>Впоследствии, на основе анархо-панка было сфор...</td>\n",
       "      <td>Какая песня стала гимном панк-движения?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1282</td>\n",
       "      <td>18076</td>\n",
       "      <td>После этого из цифровых базовых матричных крис...</td>\n",
       "      <td>Каким методом модель ЦП доводится до ума?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>689</td>\n",
       "      <td>19755</td>\n",
       "      <td>Хозяевами паразитических грибов чаще всего явл...</td>\n",
       "      <td>При какой рекомбинации у высших грибов диплоид...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1455</td>\n",
       "      <td>36313</td>\n",
       "      <td>Аморальное деяние может обрести статус преступ...</td>\n",
       "      <td>Когда деяние совершается в соответствующую уго...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>432</td>\n",
       "      <td>12545</td>\n",
       "      <td>Трудно определить, какой язык программирования...</td>\n",
       "      <td>Где может исполняться программа на языке треть...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0          1361         6463   \n",
       "1          1403        34696   \n",
       "2          1435        13751   \n",
       "3           341        38544   \n",
       "4          1317        14589   \n",
       "5           412        26912   \n",
       "6          1282        18076   \n",
       "7           689        19755   \n",
       "8          1455        36313   \n",
       "9           432        12545   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  Передний мозг сильно развит, это самая большая...   \n",
       "1  Мирмекологи исследуют муравьёв как в лаборатор...   \n",
       "2  Волновая: свет представляет собой волну в неви...   \n",
       "3  Живые организмы подчиняются началам термодинам...   \n",
       "4  Файлы нелатинского текста в Юникоде всегда зан...   \n",
       "5  Впоследствии, на основе анархо-панка было сфор...   \n",
       "6  После этого из цифровых базовых матричных крис...   \n",
       "7  Хозяевами паразитических грибов чаще всего явл...   \n",
       "8  Аморальное деяние может обрести статус преступ...   \n",
       "9  Трудно определить, какой язык программирования...   \n",
       "\n",
       "                                            question  \n",
       "0  В какой мифологии два ворона Хугин и Мунин шеп...  \n",
       "1  Когда инсайдер покупает или гипотезы чего эвол...  \n",
       "2  Какие предположения, по мнению Ньютона, допуст...  \n",
       "3  В каких условиях метаболизм поддерживает поряд...  \n",
       "4  Каким мелодиям Прокофьева особенно не укладыва...  \n",
       "5            Какая песня стала гимном панк-движения?  \n",
       "6          Каким методом модель ЦП доводится до ума?  \n",
       "7  При какой рекомбинации у высших грибов диплоид...  \n",
       "8  Когда деяние совершается в соответствующую уго...  \n",
       "9  Где может исполняться программа на языке треть...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = pd.read_csv(\"sdsj_A_test.csv\")\n",
    "dftest.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check class balance (seems like we'll have imbalance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJI6DAdJUofhIEnq+H++hUj4kLhMNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d7418ceb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dftrain[\"target\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(estimator, X, y, question_ids, paragraph_ids, target_class):\n",
    "    # It works next way:\n",
    "    #  to avoid overfitting for paragraph/question:\n",
    "    #    split paragraphs to few train/test sets (by id)\n",
    "    #    split questions to few train/test sets (by id)\n",
    "    #  for each paragraph/question sets pair:\n",
    "    #    get record with given paragraph anf question\n",
    "    #    train classifier of train subset\n",
    "    #    classify test set, store score\n",
    "    #  return mean score and standart deviation\n",
    "    X_np = np.array(X)\n",
    "    y_np = np.array(y)\n",
    "    \n",
    "    question_ids_unique_np = np.array(sorted(list(question_ids.unique())))\n",
    "    paragraph_ids_unique_np = np.array(sorted(list(paragraph_ids.unique())))\n",
    "    \n",
    "    initial = estimator.get_params()\n",
    "    \n",
    "    n_splits_sqr = 3\n",
    "    paragraph_kfold = KFold(n_splits=n_splits_sqr)\n",
    "    question_kfold = KFold(n_splits=n_splits_sqr)\n",
    "    \n",
    "    pb = IntProgress(min=0, max=n_splits_sqr * n_splits_sqr, value=0)\n",
    "    display(pb)\n",
    "        \n",
    "    scores = []\n",
    "    \n",
    "    for paragraph_train_index, paragraph_test_index in paragraph_kfold.split(paragraph_ids_unique_np):\n",
    "        paragraph_idx_train = np.isin(paragraph_ids, paragraph_ids_unique_np[paragraph_train_index])\n",
    "        paragraph_idx_test = np.isin(paragraph_ids, paragraph_ids_unique_np[paragraph_test_index])\n",
    "        \n",
    "        for question_train_index, question_test_index in question_kfold.split(question_ids_unique_np):\n",
    "            question_idx_train = np.isin(question_ids, question_ids_unique_np[question_train_index])\n",
    "            question_idx_test = np.isin(question_ids, question_ids_unique_np[question_test_index])\n",
    "            \n",
    "            idx_train = np.logical_and(question_idx_train, paragraph_idx_train)\n",
    "            idx_test = np.logical_and(question_idx_test, paragraph_idx_test)\n",
    "            \n",
    "            X_train = X_np[idx_train]\n",
    "            y_train = y_np[idx_train]\n",
    "            X_test = X_np[idx_test]\n",
    "            y_test = y_np[idx_test]\n",
    "            \n",
    "            estimator.set_params(**initial)\n",
    "            estimator.fit(X_train, y_train)\n",
    "            \n",
    "            target_class_index = estimator.classes_.tolist().index(target_class)\n",
    "            prediction = estimator.predict_proba(X_test)[:, target_class_index]\n",
    "            score = roc_auc_score(y_test, prediction)\n",
    "            scores.append(score)\n",
    "            \n",
    "            pb.value += 1\n",
    "    scores_np = np.array(scores)\n",
    "    return scores_np.mean(), scores_np.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8aee83e1e844e0965a44e901d15d1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'isin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-da1fee3a34a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m    \u001b[0mdftrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"paragraph_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m    \u001b[0mdftrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"question_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m    1)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-49ef605519cf>\u001b[0m in \u001b[0;36mcv\u001b[1;34m(estimator, X, y, question_ids, paragraph_ids, target_class)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mparagraph_train_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparagraph_test_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparagraph_kfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph_ids_unique_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mparagraph_idx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparagraph_ids_unique_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparagraph_train_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mparagraph_idx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparagraph_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparagraph_ids_unique_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparagraph_test_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'isin'"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "cv(DummyClassifier(),\n",
    "   np.zeros([len(dftrain), 1]),\n",
    "   dftrain[\"target\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   dftrain[\"question_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preparations\n",
    "\n",
    "I'll use next conversions:\n",
    "- split paragraph to individual sentences (in some cases question have most relevant sentences)\n",
    "- lemmatize sentences\n",
    "- concatenate lemmatized sentences (so I'll have lemmatized paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_paragraph(df):\n",
    "    def _split_sentences(text):\n",
    "        return list(filter(lambda sentence: sentence != \"\", \n",
    "                           map(lambda sentence: sentence.strip(), \n",
    "                               re.split(\"[.!?]\", text))))\n",
    "    \n",
    "    df[\"paragraph_sentences\"] = [_split_sentences(paragraph)\n",
    "                                 for paragraph in tqdm(df[\"paragraph\"])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 119398/119398 [00:03<00:00, 30462.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 74286/74286 [00:02<00:00, 30839.34it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = split_paragraph(dftrain)\n",
    "dftest = split_paragraph(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()\n",
    "\n",
    "\n",
    "@lru_cache(2000000)\n",
    "def _lemmatize_word(word):\n",
    "    return morph.parse(word)[0].normal_form\n",
    "\n",
    "\n",
    "stop_morphs = [_lemmatize_word(word) for word in stopwords.words('russian')]\n",
    "\n",
    "\n",
    "@lru_cache(200000)\n",
    "def _lemmatize_text(text):\n",
    "    words = filter(lambda token: re.match(\"\\w+\", token),\n",
    "                   wordpunct_tokenize(text.lower()))\n",
    "    return \" \".join(map(_lemmatize_word, words))\n",
    "\n",
    "\n",
    "def lemmatize_question(df):\n",
    "    df[\"question_lemmatized\"] = [_lemmatize_text(question)\n",
    "                                 for question in tqdm(df[\"question\"])]\n",
    "    return df\n",
    "\n",
    "\n",
    "def lemmatize_paragraph_sentences(df):\n",
    "    df[\"paragraph_sentences_lemmatized\"] = [[_lemmatize_text(sentence) for sentence in sentences]\n",
    "                                            for sentences in tqdm(df[\"paragraph_sentences\"])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 119398/119398 [00:17<00:00, 6661.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 119398/119398 [00:03<00:00, 35164.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 74286/74286 [00:03<00:00, 22241.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 74286/74286 [00:07<00:00, 10292.60it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = lemmatize_question(lemmatize_paragraph_sentences(dftrain))\n",
    "dftest = lemmatize_question(lemmatize_paragraph_sentences(dftest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize_paragraph(df):\n",
    "    df[\"paragraph_lemmatized\"] = [\" \".join(sentences)\n",
    "                                  for sentences in tqdm(df[\"paragraph_sentences_lemmatized\"])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 119398/119398 [00:00<00:00, 284583.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 74286/74286 [00:00<00:00, 250512.21it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = lemmatize_paragraph(dftrain)\n",
    "dftest = lemmatize_paragraph(dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations:\n",
    "\n",
    "There I'll:\n",
    "- calculate IDF on train set words (for lemmatized texts)\n",
    "- train word2vec on lemmatized texts (mayeb it'll be better to use pretrained model from https://nlpub.ru/Russian_Distributional_Thesaurus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_idfs(df):\n",
    "    def _get_unique_texts(df):\n",
    "        return set(df[\"paragraph_lemmatized\"].unique()) | set(df[\"question_lemmatized\"].unique())\n",
    "    \n",
    "    texts = _get_unique_texts(df)\n",
    "    vectorizer = CountVectorizer()\n",
    "    counts = np.asarray(vectorizer.fit_transform(texts).sum(axis=0))[0]\n",
    "    counts_inv = np.divide(np.ones(counts.shape), counts)\n",
    "    idf_values = np.log(counts_inv)\n",
    "    return {\n",
    "        word: idf\n",
    "        for word, idf in zip(vectorizer.get_feature_names(), idf_values)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idfs = calculate_idfs(dftrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_word2vec(df):\n",
    "    sentences = list(df[\"paragraph_lemmatized\"]) + list(df[\"question\"])\n",
    "    return Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = train_word2vec(dftrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline (question to paragraph sentence intersections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define sentence-to-question intersection operation next way:\n",
    "- it get's 2 lemmatized texts\n",
    "- for each word1, word2 pair (where word1 in text1, word2 in text2 and word1, word2 not in stop words):\n",
    "  - it get's cosine similarity of word2vec vector\n",
    "  - if similarity > threshold - it store word pair in set\n",
    "- it's return builded set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection_generator(word2vec, threshold, stopwords):\n",
    "    def intersection(text1, text2):\n",
    "        words1 = set(text1.split(' '))\n",
    "        words2 = set(text2.split(' '))\n",
    "        result = set()\n",
    "        for word1 in words1:\n",
    "            if word1 in stopwords:\n",
    "                continue\n",
    "            for word2 in words2:\n",
    "                if word2 in stopwords:\n",
    "                    continue\n",
    "                if word1 == word2:\n",
    "                    similarity = 1.0\n",
    "                elif word1 in word2vec and word2 in word2vec:\n",
    "                    similarity = word2vec.similarity(word1, word2)\n",
    "                else:\n",
    "                    similarity = 0.0\n",
    "                if similarity >= threshold:\n",
    "                    result.add(word1 + \":\" + word2)\n",
    "        return [words.split(':')[:2] for words in result]\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec_intersection = intersection_generator(word2vec, 0.8, stop_morphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check this intersection on few paragraph/question pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0] 0.0\n"
     ]
    }
   ],
   "source": [
    "intersection = [len(word2vec_intersection(sentence, dftrain[\"question_lemmatized\"][0]))\n",
    "                for sentence in dftrain[\"paragraph_sentences_lemmatized\"][0]]\n",
    "print(list(intersection), dftrain.loc[0, \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0] 0.0\n"
     ]
    }
   ],
   "source": [
    "intersection = [len(word2vec_intersection(sentence, dftrain[\"question_lemmatized\"][1]))\n",
    "                for sentence in dftrain[\"paragraph_sentences_lemmatized\"][1]]\n",
    "print(list(intersection), dftrain.loc[1, \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 0] 1.0\n"
     ]
    }
   ],
   "source": [
    "intersection = [len(word2vec_intersection(sentence, dftrain[\"question_lemmatized\"][7]))\n",
    "                for sentence in dftrain[\"paragraph_sentences_lemmatized\"][7]]\n",
    "print(list(intersection), dftrain.loc[7, \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 10] 1.0\n"
     ]
    }
   ],
   "source": [
    "intersection = [len(word2vec_intersection(sentence, dftrain[\"question_lemmatized\"][8]))\n",
    "                for sentence in dftrain[\"paragraph_sentences_lemmatized\"][8]]\n",
    "print(list(intersection), dftrain.loc[8, \"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define paragraph-to-question intersection function next way:\n",
    "- it's get paragraph sentences, question and sentence-to-question intersection function\n",
    "- for each sentence:\n",
    "  - get intersection (as pairs of sentence and question words)\n",
    "  - store intersection word pairs in set\n",
    "  - store intersection size in list\n",
    "- return total intersection words set and sentence intersection sizes (as numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paragraph_sentences_question_intersection(paragraph_sentences, question, intersection_function):\n",
    "    intersection = set()\n",
    "    intersection_sizes = []\n",
    "    for paragraph_sentence in paragraph_sentences:\n",
    "        sentence_intersection = intersection_function(paragraph_sentence, question)\n",
    "        intersection_sizes.append(len(sentence_intersection))\n",
    "        for isect in sentence_intersection:\n",
    "            word1, word2 = isect[:2]\n",
    "            intersection.add(word1 + \":\" + word2)\n",
    "    return [pair.split(\":\") for pair in intersection], np.array(intersection_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], array([0, 0, 0, 0]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_sentences_question_intersection(dftrain[\"paragraph_sentences_lemmatized\"][0],\n",
    "                                          dftrain[\"question_lemmatized\"][0],\n",
    "                                          word2vec_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], array([0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_sentences_question_intersection(dftrain[\"paragraph_sentences_lemmatized\"][1],\n",
    "                                          dftrain[\"question_lemmatized\"][1],\n",
    "                                          word2vec_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['монах', 'монах'],\n",
       "  ['использовать', 'использовать'],\n",
       "  ['признак', 'признак'],\n",
       "  ['летописец', 'летописец'],\n",
       "  ['киевский', 'киевский'],\n",
       "  ['нестор', 'нестор']],\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 6, 0]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_sentences_question_intersection(dftrain[\"paragraph_sentences_lemmatized\"][7],\n",
    "                                          dftrain[\"question_lemmatized\"][7],\n",
    "                                          word2vec_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['рекламный', 'рекламный'],\n",
       "  ['понять', 'понять'],\n",
       "  ['канал', 'канал'],\n",
       "  ['сайт', 'сайт'],\n",
       "  ['сбор', 'сбор'],\n",
       "  ['подключаться', 'подключаться'],\n",
       "  ['точный', 'точный'],\n",
       "  ['клиент', 'клиент'],\n",
       "  ['информация', 'информация'],\n",
       "  ['прийти', 'прийти']],\n",
       " array([ 0,  0,  0,  1, 10]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_sentences_question_intersection(dftrain[\"paragraph_sentences_lemmatized\"][8],\n",
    "                                          dftrain[\"question_lemmatized\"][8],\n",
    "                                          word2vec_intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store intersection and intersection sizes in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentences_intersection(df, intersection_function):\n",
    "    intersection_params = [paragraph_sentences_question_intersection(df.loc[i, \"paragraph_sentences_lemmatized\"],\n",
    "                                                                     df.loc[i, \"question_lemmatized\"],\n",
    "                                                                     intersection_function)\n",
    "                           for i in tqdm(range(len(df)))]\n",
    "    intersections = [row[0] for row in intersection_params]\n",
    "    intersection_sizes = [row[1] for row in intersection_params]\n",
    "    df[\"intersections\"] = intersections\n",
    "    df[\"intersection_sizes\"] = intersection_sizes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 119398/119398 [08:17<00:00, 240.07it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 74286/74286 [05:57<00:00, 207.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = sentences_intersection(dftrain, word2vec_intersection)\n",
    "dftest = sentences_intersection(dftest, word2vec_intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate next features:\n",
    "- paragraph/question intersection length (count of word pairs in intersection)\n",
    "- paragraph/question intersection IDF (sum of intersection word pair's IDF)\n",
    "- on intersection size per individual paragraph sentences:\n",
    "  - divide to question word count:\n",
    "    - get mean value\n",
    "    - get standart deviation\n",
    "  - divide to sentence word count:\n",
    "    - get mean value\n",
    "    - get standart deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_intersection_features(df, intersection_function, idfs):\n",
    "    def _mean(val):\n",
    "        if len(val.ravel()) == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return val.mean()\n",
    "        \n",
    "    features = np.zeros([len(df), 6])\n",
    "    names = ['sentence_intersection_sizes', 'sentence_intersection_idf', \n",
    "             'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "             'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question']\n",
    "    for i in tqdm(range(0, len(df))):\n",
    "        intersection = df.loc[i, \"intersections\"]\n",
    "        intersection_sizes = df.loc[i, \"intersection_sizes\"]\n",
    "        intersection_idf = np.array([idfs.get(word1, 0) * idfs.get(word2, 0)\n",
    "                                               for word1, word2 in intersection]).sum()\n",
    "        intersection_sizes_to_question = intersection_sizes / len(df.loc[i, \"question_lemmatized\"].split(\" \"))\n",
    "        intersection_sizes_to_paragraph = np.divide(intersection_sizes,\n",
    "                                                    np.array([len(sentence.split(\" \"))\n",
    "                                                              for sentence in df.loc[i, \"paragraph_sentences_lemmatized\"]]))\n",
    "        features[i, 0] = len(intersection)\n",
    "        features[i, 1] = intersection_idf.sum()\n",
    "        features[i, 2] = _mean(intersection_sizes_to_paragraph)\n",
    "        features[i, 3] = _mean(intersection_sizes_to_question)\n",
    "        features[i, 4] = intersection_sizes_to_paragraph.std()\n",
    "        features[i, 5] = intersection_sizes_to_question.std()\n",
    "    for i, name in enumerate(names):\n",
    "        df[name] = features[:, i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 119398/119398 [00:39<00:00, 3059.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 74286/74286 [00:27<00:00, 2668.55it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = sentence_intersection_features(dftrain, word2vec_intersection, idfs)\n",
    "dftest = sentence_intersection_features(dftest, word2vec_intersection, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97453143d234cd3b3a3fcd0b3fc316d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99225030712313389, 0.0011922117701041418)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question']\n",
    "cv(XGBClassifier(),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole paragraph intersection\n",
    "\n",
    "Let's calculate intersections per whole paragraph (by intersection with concatenated sentences) and store next features:\n",
    "- intersection length (word pair count)\n",
    "- question length (word count)\n",
    "- paragraph length (word count)\n",
    "- paragraph IDF\n",
    "- question IDF\n",
    "- intersection IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paragraph_intersection_features(df, intersection_func, idfs):\n",
    "    features = np.zeros([len(df), 6])\n",
    "    names = ['len_paragraph', 'len_question', 'len_intersection',\n",
    "             'idf_paragraph', 'idf_question', 'idf_intersection']\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.loc[i]\n",
    "        paragraph_words = set(row[\"paragraph_lemmatized\"].split(' '))\n",
    "        question_words = set(row[\"question_lemmatized\"].split(' '))\n",
    "        intersection = intersection_func(\" \".join(paragraph_words), \" \".join(question_words))\n",
    "        intersection_flat = list(chain(*intersection))\n",
    "        features[i, 0] = len(paragraph_words)\n",
    "        features[i, 1] = len(question_words)\n",
    "        features[i, 2] = len(intersection)\n",
    "        features[i, 3] = np.sum([idfs.get(word, 0) for word in paragraph_words])\n",
    "        features[i, 4] = np.sum([idfs.get(word, 0) for word in question_words])\n",
    "        features[i, 5] = np.sum([idfs.get(word, 0) for word in intersection_flat])\n",
    "    for i, name in enumerate(names):\n",
    "        df[name] = features[:, i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 119398/119398 [07:52<00:00, 252.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 74286/74286 [04:44<00:00, 261.50it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = paragraph_intersection_features(dftrain, word2vec_intersection, idfs)\n",
    "dftest = paragraph_intersection_features(dftest, word2vec_intersection, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c582cbb0a044388b88fa1be6eb7c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99486971830848014, 0.00091789539933222154)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'len_paragraph', 'len_question', 'len_intersection',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection']\n",
    "cv(XGBClassifier(),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-paragraph distances\n",
    "\n",
    "Let's define text \"distances\" next way (based on WMD):\n",
    "- get 2 texts\n",
    "- for each word of text1 - get most similar word from text 2 (by cosine distance between word2vec vectors) and store their similarity\n",
    "- get mean similarity value (as \"distance\") and similarities standart deviation\n",
    "\n",
    "And now let's calculate this distances and deviations between question and paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _pair_distance(question, paragraph, word2vec):\n",
    "    def _text_vectors(text):\n",
    "        result = np.array([word2vec[word]\n",
    "                           for word in text\n",
    "                           if word in word2vec])\n",
    "        if len(result) == 0:\n",
    "            return np.ones([1, word2vec.vector_size]) * 0.01\n",
    "        return result\n",
    "    \n",
    "    question_vectors = _text_vectors(question)\n",
    "    paragraph_vectors = _text_vectors(paragraph)\n",
    "    distances = cosine_distances(question_vectors, paragraph_vectors)\n",
    "    word_min_distances = np.zeros([len(question_vectors)])\n",
    "    for i in range(0, len(question_vectors)):\n",
    "        word_min_distances[i] = distances[i, :].min()\n",
    "    return word_min_distances.mean(), word_min_distances.std()\n",
    "\n",
    "\n",
    "def pairs_distances(df, word2vec):\n",
    "    questions = df[\"question_lemmatized\"]\n",
    "    paragraphs = df[\"paragraph_lemmatized\"]\n",
    "    features = np.zeros([len(questions), 2])\n",
    "    names = [\"distance_mean\", \"distance_std\"]\n",
    "    for i in tqdm(range(0, len(paragraphs))):\n",
    "        features[i, :] = _pair_distance(questions[i], paragraphs[i], word2vec)\n",
    "    for i, name in enumerate(names):\n",
    "        df[name] = features[:, i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 119398/119398 [15:17<00:00, 130.17it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 74286/74286 [13:20<00:00, 92.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = pairs_distances(dftrain, word2vec)\n",
    "dftest = pairs_distances(dftest, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2e4321a7fc48d28f84b5e4c05ec7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99496936054557006, 0.0008919097663535084)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'len_paragraph', 'len_question', 'len_intersection',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'distance_mean', 'distance_std']\n",
    "cv(XGBClassifier(),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate same distances between question and paragraph sentences and store:\n",
    "- mean distance\n",
    "- distance deviation\n",
    "- minimal distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_pairs_distances(df, word2vec):\n",
    "    questions = df[\"question_lemmatized\"]\n",
    "    paragraphs = df[\"paragraph_sentences_lemmatized\"]\n",
    "    features = np.zeros([len(questions), 3])\n",
    "    names = [\"sentence_distance_mean\", \"sentence_distance_std\", \"sentence_distance_min\"]\n",
    "    for i in tqdm(range(0, len(df))):\n",
    "        distances = []\n",
    "        for sentence in paragraphs[i]:\n",
    "            distance = _pair_distance(questions[i], sentence, word2vec)\n",
    "            distances.append(distance)\n",
    "        distances = np.array(distances)\n",
    "        features[i, 0] = distances.mean()\n",
    "        features[i, 1] = distances.std()\n",
    "        features[i, 2] = distances.min()\n",
    "    for i, name in enumerate(names):\n",
    "        df[name] = features[:, i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 119398/119398 [35:16<00:00, 56.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 74286/74286 [24:49<00:00, 37.59it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = sentence_pairs_distances(dftrain, word2vec)\n",
    "dftest = sentence_pairs_distances(dftest, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aeb1b6ab3c64756a2cc1732c1fe91d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99497564783990333, 0.00083852999428613267)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'len_paragraph', 'len_question', 'len_intersection',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'distance_mean', 'distance_std',\n",
    "           'sentence_distance_mean', 'sentence_distance_std', 'sentence_distance_min']\n",
    "cv(XGBClassifier(),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00bdd7cae957432ea1a15f484767c510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99498953610968521, 0.00090323832211273059)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'len_paragraph', 'len_question', 'len_intersection',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'distance_mean', 'distance_std',\n",
    "           'sentence_distance_min']\n",
    "cv(XGBClassifier(),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319ed07b8b8c458f887ba7e94298444a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99544184122644708, 0.00082143139051064071)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'len_paragraph', 'len_question', 'len_intersection',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'distance_mean', 'distance_std',\n",
    "           'sentence_distance_min']\n",
    "cv(XGBClassifier(n_estimators=350),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levenshtein distance-based features\n",
    "\n",
    "Let's add features based on parargraph/question and paragraph sentence/question levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein_features(df):\n",
    "    features = np.zeros([len(df), 4])\n",
    "    names = ['levenshtein_to_question', 'levenshtein_to_paragraph',\n",
    "             'levenshtein_sentence_to_question', 'levenshtein_sentence_to_paragraph']\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.loc[i]\n",
    "        question = df.loc[i, \"question_lemmatized\"]\n",
    "        paragraph = df.loc[i, \"paragraph_lemmatized\"]\n",
    "        sentences = df.loc[i, \"paragraph_sentences_lemmatized\"]\n",
    "        question_paragraph_distance = distance(question, paragraph)\n",
    "        features[i, 0] = question_paragraph_distance / len(question)\n",
    "        features[i, 1] = question_paragraph_distance / len(paragraph)\n",
    "        sentence_distances = []\n",
    "        for sentence in sentences:\n",
    "            sentence_distances.append(distance(question, sentence))\n",
    "        sentence_distances_np = np.array(sentence_distances)\n",
    "        features[i, 2] = sentence_distances_np.min() / len(question)\n",
    "        features[i, 3] = sentence_distances_np.min() / len(sentences[sentence_distances_np.argmin()])\n",
    "    for i, name in enumerate(names):\n",
    "        df[name] = features[:, i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 119398/119398 [01:33<00:00, 1278.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 74286/74286 [01:02<00:00, 1188.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = levenshtein_features(dftrain)\n",
    "dftest = levenshtein_features(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6034d846580442a8955c38bb97deb4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99547023879010821, 0.00078842240781404577)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'len_paragraph', 'len_question', 'len_intersection', \n",
    "           'distance_mean', 'distance_std',\n",
    "           'sentence_distance_min',\n",
    "           'levenshtein_to_question', 'levenshtein_to_paragraph',\n",
    "           'levenshtein_sentence_to_question', 'levenshtein_sentence_to_paragraph']\n",
    "cv(XGBClassifier(n_estimators=350),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autogenerated question detection\n",
    "\n",
    "## Uppercase characters\n",
    "\n",
    "Also, automatically generated questions always have only first uppercase character. Let's add 2 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _uppercase_count(text):\n",
    "    if len(text) == 0:\n",
    "        return 0\n",
    "    count = 0\n",
    "    for chr1, chr2 in zip(text, text.upper()):\n",
    "        if chr1 == chr2:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def _question_uppercase_count(df):\n",
    "    df[\"question_uppercase_count\"] = [_uppercase_count(question) for question in tqdm(df[\"question\"])]\n",
    "    return df\n",
    "\n",
    "\n",
    "def _question_uppercase_part(df):\n",
    "    df[\"question_uppercase_part\"] = np.divide(df[\"question_uppercase_count\"],\n",
    "                                              np.array([len(question) for question in df[\"question\"]]))\n",
    "    return df\n",
    "\n",
    "def question_uppercase_features(df):\n",
    "    return _question_uppercase_part(_question_uppercase_count(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 119398/119398 [00:02<00:00, 41116.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 74286/74286 [00:01<00:00, 37828.63it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = question_uppercase_features(dftrain)\n",
    "dftest = question_uppercase_features(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7835f25cf5480286448c5a7d2215d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99558758426162874, 0.00080686351893124487)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'len_paragraph', 'len_question', 'len_intersection', \n",
    "           'distance_mean', 'distance_std',\n",
    "           'question_uppercase_count', 'question_uppercase_part',\n",
    "           'sentence_distance_min',\n",
    "           'levenshtein_to_question', 'levenshtein_to_paragraph',\n",
    "           'levenshtein_sentence_to_question', 'levenshtein_sentence_to_paragraph']\n",
    "cv(XGBClassifier(n_estimators=350),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tags\n",
    "\n",
    "Also let's add POS tag features (seems like automaticaally generated texts have different POS didtribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@lru_cache(2000000)\n",
    "def _pos(word):\n",
    "    return morph.parse(word)[0].tag.POS\n",
    "\n",
    "\n",
    "def _pos_text(text):\n",
    "    tags = list(filter(lambda pos_tag: pos_tag is not None,\n",
    "                       map(_pos, wordpunct_tokenize(text))))\n",
    "    result = {}\n",
    "    for tag in tags:\n",
    "        result[tag] = result.get(tag, 0) + 1\n",
    "    result_scaled = {}\n",
    "    for tag, count in result.items():\n",
    "        result_scaled[tag] = count / len(tags)\n",
    "    return result_scaled\n",
    "\n",
    "def pos_questions(df):\n",
    "    values = [_pos_text(question) for question in tqdm(df[\"question\"])]\n",
    "    tags = sorted(list(set(chain(*map(lambda value: list(value.keys()), values)))))\n",
    "    for tag in tqdm(tags):\n",
    "        df[tag + \"_count\"] = [row.get(tag, 0) for row in values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                       | 0/119398 [00:00<?, ?it/s]\n",
      "  0%|                                                                             | 2/119398 [00:00<1:40:00, 19.90it/s]\n",
      "  0%|                                                                            | 65/119398 [00:00<1:10:54, 28.05it/s]\n",
      "  0%|                                                                             | 190/119398 [00:00<50:03, 39.68it/s]\n",
      "  0%|▏                                                                            | 363/119398 [00:00<35:20, 56.14it/s]\n",
      "  0%|▎                                                                            | 556/119398 [00:00<25:00, 79.21it/s]\n",
      "  1%|▍                                                                           | 728/119398 [00:00<17:49, 110.96it/s]\n",
      "  1%|▌                                                                           | 958/119398 [00:00<12:42, 155.29it/s]\n",
      "  1%|▊                                                                          | 1213/119398 [00:00<09:06, 216.19it/s]\n",
      "  1%|▉                                                                          | 1485/119398 [00:00<06:34, 298.67it/s]\n",
      "  1%|█                                                                          | 1743/119398 [00:01<04:49, 406.50it/s]\n",
      "  2%|█▎                                                                         | 2024/119398 [00:01<03:34, 546.81it/s]\n",
      "  2%|█▍                                                                         | 2268/119398 [00:01<02:44, 711.14it/s]\n",
      "  2%|█▌                                                                         | 2525/119398 [00:01<02:08, 908.21it/s]\n",
      "  2%|█▊                                                                        | 2832/119398 [00:01<01:41, 1151.44it/s]\n",
      "  3%|█▉                                                                        | 3121/119398 [00:01<01:22, 1404.97it/s]\n",
      "  3%|██                                                                        | 3394/119398 [00:01<01:10, 1644.38it/s]\n",
      "  3%|██▎                                                                       | 3700/119398 [00:01<01:00, 1909.32it/s]\n",
      "  3%|██▍                                                                       | 4005/119398 [00:01<00:53, 2150.54it/s]\n",
      "  4%|██▋                                                                       | 4421/119398 [00:01<00:45, 2514.93it/s]\n",
      "  4%|██▉                                                                       | 4835/119398 [00:02<00:40, 2850.58it/s]\n",
      "  4%|███▏                                                                      | 5240/119398 [00:02<00:36, 3128.44it/s]\n",
      "  5%|███▌                                                                      | 5670/119398 [00:02<00:33, 3406.81it/s]\n",
      "  5%|███▊                                                                      | 6063/119398 [00:02<00:31, 3548.41it/s]\n",
      "  5%|████                                                                      | 6500/119398 [00:02<00:30, 3760.34it/s]\n",
      "  6%|████▎                                                                     | 6941/119398 [00:02<00:28, 3934.13it/s]\n",
      "  6%|████▌                                                                     | 7356/119398 [00:02<00:28, 3928.25it/s]\n",
      "  7%|████▊                                                                     | 7764/119398 [00:02<00:28, 3876.18it/s]\n",
      "  7%|█████                                                                     | 8163/119398 [00:02<00:28, 3898.03it/s]\n",
      "  7%|█████▍                                                                    | 8698/119398 [00:02<00:26, 4243.40it/s]\n",
      "  8%|█████▋                                                                    | 9161/119398 [00:03<00:25, 4352.28it/s]\n",
      "  8%|██████                                                                    | 9707/119398 [00:03<00:23, 4634.19it/s]\n",
      "  9%|██████▎                                                                  | 10239/119398 [00:03<00:22, 4820.38it/s]\n",
      "  9%|██████▌                                                                  | 10732/119398 [00:03<00:22, 4782.04it/s]\n",
      "  9%|██████▉                                                                  | 11258/119398 [00:03<00:21, 4915.87it/s]\n",
      " 10%|███████▏                                                                 | 11774/119398 [00:03<00:21, 4986.47it/s]\n",
      " 10%|███████▌                                                                 | 12314/119398 [00:03<00:20, 5103.54it/s]\n",
      " 11%|███████▊                                                                 | 12860/119398 [00:03<00:20, 5205.31it/s]\n",
      " 11%|████████▏                                                                | 13416/119398 [00:03<00:19, 5306.67it/s]\n",
      " 12%|████████▌                                                                | 14010/119398 [00:03<00:19, 5481.82it/s]\n",
      " 12%|████████▉                                                                | 14562/119398 [00:04<00:19, 5349.28it/s]\n",
      " 13%|█████████▏                                                               | 15107/119398 [00:04<00:19, 5378.90it/s]\n",
      " 13%|█████████▌                                                               | 15684/119398 [00:04<00:18, 5482.50it/s]\n",
      " 14%|█████████▉                                                               | 16235/119398 [00:04<00:18, 5490.52it/s]\n",
      " 14%|██████████▎                                                              | 16888/119398 [00:04<00:17, 5765.60it/s]\n",
      " 15%|██████████▋                                                              | 17470/119398 [00:04<00:17, 5705.17it/s]\n",
      " 15%|███████████                                                              | 18144/119398 [00:04<00:16, 5980.44it/s]\n",
      " 16%|███████████▍                                                             | 18748/119398 [00:04<00:17, 5909.90it/s]\n",
      " 16%|███████████▊                                                             | 19354/119398 [00:04<00:16, 5953.93it/s]\n",
      " 17%|████████████▏                                                            | 19990/119398 [00:04<00:16, 6069.97it/s]\n",
      " 17%|████████████▌                                                            | 20600/119398 [00:05<00:16, 5885.16it/s]\n",
      " 18%|████████████▉                                                            | 21229/119398 [00:05<00:16, 6000.82it/s]\n",
      " 18%|█████████████▍                                                           | 21882/119398 [00:05<00:15, 6150.13it/s]\n",
      " 19%|█████████████▊                                                           | 22500/119398 [00:05<00:15, 6158.83it/s]\n",
      " 19%|██████████████▏                                                          | 23183/119398 [00:05<00:15, 6345.68it/s]\n",
      " 20%|██████████████▌                                                          | 23821/119398 [00:05<00:15, 6280.59it/s]\n",
      " 20%|██████████████▉                                                          | 24469/119398 [00:05<00:14, 6329.60it/s]\n",
      " 21%|███████████████▍                                                         | 25163/119398 [00:05<00:14, 6500.90it/s]\n",
      " 22%|███████████████▊                                                         | 25816/119398 [00:05<00:14, 6470.66it/s]\n",
      " 22%|████████████████▏                                                        | 26483/119398 [00:05<00:14, 6528.96it/s]\n",
      " 23%|████████████████▋                                                        | 27210/119398 [00:06<00:13, 6734.60it/s]\n",
      " 23%|█████████████████                                                        | 27942/119398 [00:06<00:13, 6899.96it/s]\n",
      " 24%|█████████████████▌                                                       | 28635/119398 [00:06<00:13, 6757.09it/s]\n",
      " 25%|█████████████████▉                                                       | 29314/119398 [00:06<00:13, 6676.83it/s]\n",
      " 25%|██████████████████▎                                                      | 29987/119398 [00:06<00:13, 6692.45it/s]\n",
      " 26%|██████████████████▋                                                      | 30658/119398 [00:06<00:13, 6647.67it/s]\n",
      " 26%|███████████████████▏                                                     | 31390/119398 [00:06<00:12, 6835.79it/s]\n",
      " 27%|███████████████████▌                                                     | 32093/119398 [00:06<00:12, 6882.54it/s]\n",
      " 27%|████████████████████                                                     | 32785/119398 [00:06<00:12, 6893.47it/s]\n",
      " 28%|████████████████████▍                                                    | 33525/119398 [00:06<00:12, 7037.74it/s]\n",
      " 29%|████████████████████▉                                                    | 34231/119398 [00:07<00:12, 6741.41it/s]\n",
      " 29%|█████████████████████▎                                                   | 34945/119398 [00:07<00:12, 6856.00it/s]\n",
      " 30%|█████████████████████▊                                                   | 35639/119398 [00:07<00:12, 6880.72it/s]\n",
      " 30%|██████████████████████▏                                                  | 36342/119398 [00:07<00:11, 6924.57it/s]\n",
      " 31%|██████████████████████▋                                                  | 37037/119398 [00:07<00:11, 6890.67it/s]\n",
      " 32%|███████████████████████                                                  | 37728/119398 [00:07<00:12, 6715.23it/s]\n",
      " 32%|███████████████████████▌                                                 | 38474/119398 [00:07<00:11, 6922.31it/s]\n",
      " 33%|███████████████████████▉                                                 | 39170/119398 [00:07<00:11, 6851.40it/s]\n",
      " 33%|████████████████████████▍                                                | 39928/119398 [00:07<00:11, 7054.58it/s]\n",
      " 34%|████████████████████████▊                                                | 40664/119398 [00:08<00:11, 7143.26it/s]\n",
      " 35%|█████████████████████████▎                                               | 41381/119398 [00:08<00:11, 7087.35it/s]\n",
      " 35%|█████████████████████████▊                                               | 42179/119398 [00:08<00:10, 7333.20it/s]\n",
      " 36%|██████████████████████████▏                                              | 42916/119398 [00:08<00:10, 7182.87it/s]\n",
      " 37%|██████████████████████████▋                                              | 43677/119398 [00:08<00:10, 7305.62it/s]\n",
      " 37%|███████████████████████████▏                                             | 44419/119398 [00:08<00:10, 7339.26it/s]\n",
      " 38%|███████████████████████████▌                                             | 45155/119398 [00:08<00:10, 7345.20it/s]\n",
      " 38%|████████████████████████████                                             | 45916/119398 [00:08<00:09, 7422.42it/s]\n",
      " 39%|████████████████████████████▌                                            | 46660/119398 [00:08<00:10, 7190.36it/s]\n",
      " 40%|████████████████████████████▉                                            | 47382/119398 [00:08<00:10, 7177.61it/s]\n",
      " 40%|█████████████████████████████▍                                           | 48102/119398 [00:09<00:10, 7120.08it/s]\n",
      " 41%|█████████████████████████████▊                                           | 48822/119398 [00:09<00:09, 7143.61it/s]\n",
      " 42%|██████████████████████████████▎                                          | 49590/119398 [00:09<00:09, 7296.22it/s]\n",
      " 42%|██████████████████████████████▊                                          | 50322/119398 [00:09<00:09, 6969.26it/s]\n",
      " 43%|███████████████████████████████▏                                         | 51098/119398 [00:09<00:09, 7188.79it/s]\n",
      " 43%|███████████████████████████████▋                                         | 51822/119398 [00:09<00:09, 7129.31it/s]\n",
      " 44%|████████████████████████████████▏                                        | 52582/119398 [00:09<00:09, 7264.00it/s]\n",
      " 45%|████████████████████████████████▌                                        | 53321/119398 [00:09<00:09, 7300.97it/s]\n",
      " 45%|█████████████████████████████████                                        | 54054/119398 [00:09<00:09, 7086.86it/s]\n",
      " 46%|█████████████████████████████████▍                                       | 54766/119398 [00:09<00:09, 7085.75it/s]\n",
      " 46%|█████████████████████████████████▉                                       | 55477/119398 [00:10<00:09, 7092.88it/s]\n",
      " 47%|██████████████████████████████████▍                                      | 56267/119398 [00:10<00:08, 7306.74it/s]\n",
      " 48%|██████████████████████████████████▉                                      | 57048/119398 [00:10<00:08, 7450.39it/s]\n",
      " 48%|███████████████████████████████████▎                                     | 57796/119398 [00:10<00:08, 7459.08it/s]\n",
      " 49%|███████████████████████████████████▊                                     | 58624/119398 [00:10<00:07, 7687.48it/s]\n",
      " 50%|████████████████████████████████████▎                                    | 59396/119398 [00:10<00:07, 7506.06it/s]\n",
      " 50%|████████████████████████████████████▊                                    | 60150/119398 [00:10<00:08, 7182.82it/s]\n",
      " 51%|█████████████████████████████████████▏                                   | 60874/119398 [00:10<00:08, 7011.45it/s]\n",
      " 52%|█████████████████████████████████████▋                                   | 61676/119398 [00:10<00:07, 7286.08it/s]\n",
      " 52%|██████████████████████████████████████▏                                  | 62454/119398 [00:10<00:07, 7427.14it/s]\n",
      " 53%|██████████████████████████████████████▋                                  | 63202/119398 [00:11<00:07, 7354.94it/s]\n",
      " 54%|███████████████████████████████████████▏                                 | 64036/119398 [00:11<00:07, 7624.86it/s]\n",
      " 54%|███████████████████████████████████████▋                                 | 64844/119398 [00:11<00:07, 7755.64it/s]\n",
      " 55%|████████████████████████████████████████▏                                | 65632/119398 [00:11<00:06, 7792.23it/s]\n",
      " 56%|████████████████████████████████████████▋                                | 66489/119398 [00:11<00:06, 8010.05it/s]\n",
      " 56%|█████████████████████████████████████████▏                               | 67294/119398 [00:11<00:06, 7938.63it/s]\n",
      " 57%|█████████████████████████████████████████▋                               | 68091/119398 [00:11<00:06, 7784.36it/s]\n",
      " 58%|██████████████████████████████████████████                               | 68872/119398 [00:11<00:06, 7722.39it/s]\n",
      " 58%|██████████████████████████████████████████▌                              | 69690/119398 [00:11<00:06, 7853.80it/s]\n",
      " 59%|███████████████████████████████████████████                              | 70478/119398 [00:12<00:06, 7756.85it/s]\n",
      " 60%|███████████████████████████████████████████▌                             | 71256/119398 [00:12<00:06, 7559.90it/s]\n",
      " 60%|████████████████████████████████████████████                             | 72015/119398 [00:12<00:06, 7568.62it/s]\n",
      " 61%|████████████████████████████████████████████▍                            | 72774/119398 [00:12<00:06, 6912.39it/s]\n",
      " 62%|████████████████████████████████████████████▉                            | 73478/119398 [00:12<00:06, 6828.58it/s]\n",
      " 62%|█████████████████████████████████████████████▎                           | 74170/119398 [00:12<00:06, 6735.36it/s]\n",
      " 63%|█████████████████████████████████████████████▊                           | 74850/119398 [00:12<00:06, 6694.52it/s]\n",
      " 63%|██████████████████████████████████████████████▏                          | 75524/119398 [00:12<00:07, 6224.58it/s]\n",
      " 64%|██████████████████████████████████████████████▌                          | 76233/119398 [00:12<00:06, 6460.95it/s]\n",
      " 64%|███████████████████████████████████████████████                          | 76889/119398 [00:13<00:06, 6451.70it/s]\n",
      " 65%|███████████████████████████████████████████████▍                         | 77560/119398 [00:13<00:06, 6526.93it/s]\n",
      " 66%|███████████████████████████████████████████████▊                         | 78218/119398 [00:13<00:06, 6494.08it/s]\n",
      " 66%|████████████████████████████████████████████████▏                        | 78871/119398 [00:13<00:06, 6418.24it/s]\n",
      " 67%|████████████████████████████████████████████████▋                        | 79564/119398 [00:13<00:06, 6563.42it/s]\n",
      " 67%|█████████████████████████████████████████████████                        | 80223/119398 [00:13<00:06, 6426.91it/s]\n",
      " 68%|█████████████████████████████████████████████████▍                       | 80875/119398 [00:13<00:05, 6454.31it/s]\n",
      " 68%|█████████████████████████████████████████████████▊                       | 81523/119398 [00:13<00:05, 6357.14it/s]\n",
      " 69%|██████████████████████████████████████████████████▏                      | 82161/119398 [00:13<00:06, 6072.95it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████████████████████████████████████████████████▌                      | 82773/119398 [00:13<00:06, 6086.76it/s]\n",
      " 70%|██████████████████████████████████████████████████▉                      | 83385/119398 [00:14<00:05, 6033.33it/s]\n",
      " 70%|███████████████████████████████████████████████████▎                     | 83991/119398 [00:14<00:05, 5908.55it/s]\n",
      " 71%|███████████████████████████████████████████████████▊                     | 84673/119398 [00:14<00:05, 6155.04it/s]\n",
      " 71%|████████████████████████████████████████████████████▏                    | 85332/119398 [00:14<00:05, 6279.13it/s]\n",
      " 72%|████████████████████████████████████████████████████▌                    | 86044/119398 [00:14<00:05, 6509.66it/s]\n",
      " 73%|█████████████████████████████████████████████████████                    | 86850/119398 [00:14<00:04, 6908.07it/s]\n",
      " 73%|█████████████████████████████████████████████████████▌                   | 87655/119398 [00:14<00:04, 7214.87it/s]\n",
      " 74%|██████████████████████████████████████████████████████                   | 88435/119398 [00:14<00:04, 7380.72it/s]\n",
      " 75%|██████████████████████████████████████████████████████▌                  | 89182/119398 [00:14<00:04, 7374.10it/s]\n",
      " 75%|███████████████████████████████████████████████████████                  | 90059/119398 [00:14<00:03, 7743.58it/s]\n",
      " 76%|███████████████████████████████████████████████████████▌                 | 90885/119398 [00:15<00:03, 7891.34it/s]\n",
      " 77%|████████████████████████████████████████████████████████                 | 91770/119398 [00:15<00:03, 8156.09it/s]\n",
      " 78%|████████████████████████████████████████████████████████▌                | 92593/119398 [00:15<00:03, 8177.82it/s]\n",
      " 78%|█████████████████████████████████████████████████████████                | 93416/119398 [00:15<00:03, 8120.34it/s]\n",
      " 79%|█████████████████████████████████████████████████████████▋               | 94275/119398 [00:15<00:03, 8255.31it/s]\n",
      " 80%|██████████████████████████████████████████████████████████▏              | 95104/119398 [00:15<00:02, 8204.16it/s]\n",
      " 80%|██████████████████████████████████████████████████████████▋              | 95927/119398 [00:15<00:02, 8150.57it/s]\n",
      " 81%|███████████████████████████████████████████████████████████▏             | 96747/119398 [00:15<00:02, 8164.99it/s]\n",
      " 82%|███████████████████████████████████████████████████████████▋             | 97565/119398 [00:15<00:02, 8072.46it/s]\n",
      " 82%|████████████████████████████████████████████████████████████▏            | 98374/119398 [00:15<00:02, 7819.73it/s]\n",
      " 83%|████████████████████████████████████████████████████████████▋            | 99159/119398 [00:16<00:02, 7735.52it/s]\n",
      " 84%|████████████████████████████████████████████████████████████▎           | 100049/119398 [00:16<00:02, 8040.72it/s]\n",
      " 84%|████████████████████████████████████████████████████████████▊           | 100858/119398 [00:16<00:02, 8043.12it/s]\n",
      " 85%|█████████████████████████████████████████████████████████████▎          | 101680/119398 [00:16<00:02, 8095.09it/s]\n",
      " 86%|█████████████████████████████████████████████████████████████▊          | 102562/119398 [00:16<00:02, 8299.41it/s]\n",
      " 87%|██████████████████████████████████████████████████████████████▎         | 103395/119398 [00:16<00:01, 8137.67it/s]\n",
      " 87%|██████████████████████████████████████████████████████████████▊         | 104247/119398 [00:16<00:01, 8248.55it/s]\n",
      " 88%|███████████████████████████████████████████████████████████████▎        | 105075/119398 [00:16<00:01, 8112.00it/s]\n",
      " 89%|███████████████████████████████████████████████████████████████▊        | 105889/119398 [00:16<00:01, 8059.76it/s]\n",
      " 89%|████████████████████████████████████████████████████████████████▎       | 106746/119398 [00:16<00:01, 8206.04it/s]\n",
      " 90%|████████████████████████████████████████████████████████████████▉       | 107589/119398 [00:17<00:01, 8271.65it/s]\n",
      " 91%|█████████████████████████████████████████████████████████████████▍      | 108476/119398 [00:17<00:01, 8442.20it/s]\n",
      " 92%|█████████████████████████████████████████████████████████████████▉      | 109323/119398 [00:17<00:01, 8264.53it/s]\n",
      " 92%|██████████████████████████████████████████████████████████████████▍     | 110152/119398 [00:17<00:01, 8247.27it/s]\n",
      " 93%|██████████████████████████████████████████████████████████████████▉     | 110979/119398 [00:17<00:01, 8002.16it/s]\n",
      " 94%|███████████████████████████████████████████████████████████████████▍    | 111782/119398 [00:17<00:00, 7903.74it/s]\n",
      " 94%|███████████████████████████████████████████████████████████████████▉    | 112632/119398 [00:17<00:00, 8073.34it/s]\n",
      " 95%|████████████████████████████████████████████████████████████████████▍   | 113442/119398 [00:17<00:00, 7892.04it/s]\n",
      " 96%|████████████████████████████████████████████████████████████████████▉   | 114286/119398 [00:17<00:00, 8048.52it/s]\n",
      " 96%|█████████████████████████████████████████████████████████████████████▍  | 115094/119398 [00:18<00:00, 7755.95it/s]\n",
      " 97%|█████████████████████████████████████████████████████████████████████▉  | 115923/119398 [00:18<00:00, 7908.49it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████████▍ | 116720/119398 [00:18<00:00, 7926.34it/s]\n",
      " 98%|██████████████████████████████████████████████████████████████████████▊ | 117516/119398 [00:18<00:00, 7762.18it/s]\n",
      " 99%|███████████████████████████████████████████████████████████████████████▍| 118439/119398 [00:18<00:00, 8150.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████▉| 119261/119398 [00:18<00:00, 7969.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 119398/119398 [00:18<00:00, 6426.03it/s]\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\n",
      "  6%|████▉                                                                              | 1/17 [00:00<00:06,  2.60it/s]\n",
      " 12%|█████████▊                                                                         | 2/17 [00:00<00:04,  3.11it/s]\n",
      " 18%|██████████████▋                                                                    | 3/17 [00:00<00:04,  3.44it/s]\n",
      " 24%|███████████████████▌                                                               | 4/17 [00:00<00:03,  3.93it/s]\n",
      " 29%|████████████████████████▍                                                          | 5/17 [00:01<00:03,  3.88it/s]\n",
      " 35%|█████████████████████████████▎                                                     | 6/17 [00:01<00:02,  4.34it/s]\n",
      " 41%|██████████████████████████████████▏                                                | 7/17 [00:01<00:02,  4.54it/s]\n",
      " 47%|███████████████████████████████████████                                            | 8/17 [00:01<00:01,  4.98it/s]\n",
      " 53%|███████████████████████████████████████████▉                                       | 9/17 [00:02<00:02,  3.77it/s]\n",
      " 59%|████████████████████████████████████████████████▏                                 | 10/17 [00:02<00:01,  4.09it/s]\n",
      " 65%|█████████████████████████████████████████████████████                             | 11/17 [00:02<00:01,  4.54it/s]\n",
      " 71%|█████████████████████████████████████████████████████████▉                        | 12/17 [00:02<00:01,  4.86it/s]\n",
      " 76%|██████████████████████████████████████████████████████████████▋                   | 13/17 [00:02<00:00,  5.29it/s]\n",
      " 82%|███████████████████████████████████████████████████████████████████▌              | 14/17 [00:03<00:00,  4.03it/s]\n",
      " 88%|████████████████████████████████████████████████████████████████████████▎         | 15/17 [00:03<00:00,  4.35it/s]\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▏    | 16/17 [00:03<00:00,  4.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:03<00:00,  3.70it/s]\n",
      "\n",
      "  0%|                                                                                        | 0/74286 [00:00<?, ?it/s]\n",
      "  0%|▎                                                                           | 345/74286 [00:00<00:21, 3432.43it/s]\n",
      "  1%|▊                                                                           | 745/74286 [00:00<00:20, 3584.92it/s]\n",
      "  2%|█▏                                                                         | 1178/74286 [00:00<00:19, 3779.93it/s]\n",
      "  2%|█▌                                                                         | 1562/74286 [00:00<00:19, 3797.60it/s]\n",
      "  3%|██                                                                         | 2041/74286 [00:00<00:17, 4049.16it/s]\n",
      "  3%|██▌                                                                        | 2495/74286 [00:00<00:17, 4178.96it/s]\n",
      "  4%|███                                                                        | 3003/74286 [00:00<00:16, 4413.68it/s]\n",
      "  5%|███▌                                                                       | 3495/74286 [00:00<00:15, 4554.13it/s]\n",
      "  5%|████                                                                       | 3969/74286 [00:00<00:15, 4608.17it/s]\n",
      "  6%|████▌                                                                      | 4547/74286 [00:01<00:14, 4906.44it/s]\n",
      "  7%|█████                                                                      | 5046/74286 [00:01<00:14, 4931.01it/s]\n",
      "  8%|█████▋                                                                     | 5586/74286 [00:01<00:13, 5062.75it/s]\n",
      "  8%|██████▏                                                                    | 6151/74286 [00:01<00:13, 5225.51it/s]\n",
      "  9%|██████▋                                                                    | 6676/74286 [00:01<00:13, 5193.73it/s]\n",
      " 10%|███████▎                                                                   | 7295/74286 [00:01<00:12, 5457.07it/s]\n",
      " 11%|███████▉                                                                   | 7846/74286 [00:01<00:12, 5432.22it/s]\n",
      " 11%|████████▍                                                                  | 8418/74286 [00:01<00:11, 5515.01it/s]\n",
      " 12%|█████████                                                                  | 8984/74286 [00:01<00:11, 5549.60it/s]\n",
      " 13%|█████████▋                                                                 | 9564/74286 [00:01<00:11, 5622.21it/s]\n",
      " 14%|██████████▏                                                               | 10207/74286 [00:02<00:10, 5842.11it/s]\n",
      " 15%|██████████▊                                                               | 10795/74286 [00:02<00:10, 5818.54it/s]\n",
      " 15%|███████████▎                                                              | 11409/74286 [00:02<00:10, 5911.17it/s]\n",
      " 16%|███████████▉                                                              | 12003/74286 [00:02<00:10, 5910.73it/s]\n",
      " 17%|████████████▌                                                             | 12628/74286 [00:02<00:10, 6008.35it/s]\n",
      " 18%|█████████████▏                                                            | 13286/74286 [00:02<00:09, 6168.92it/s]\n",
      " 19%|█████████████▊                                                            | 13905/74286 [00:02<00:09, 6120.05it/s]\n",
      " 20%|██████████████▍                                                           | 14519/74286 [00:02<00:09, 6116.61it/s]\n",
      " 20%|███████████████                                                           | 15132/74286 [00:02<00:09, 6003.46it/s]\n",
      " 21%|███████████████▋                                                          | 15734/74286 [00:02<00:09, 6008.14it/s]\n",
      " 22%|████████████████▎                                                         | 16354/74286 [00:03<00:09, 6064.30it/s]\n",
      " 23%|████████████████▉                                                         | 16966/74286 [00:03<00:09, 6080.57it/s]\n",
      " 24%|█████████████████▌                                                        | 17646/74286 [00:03<00:09, 6279.75it/s]\n",
      " 25%|██████████████████▏                                                       | 18276/74286 [00:03<00:09, 6156.59it/s]\n",
      " 25%|██████████████████▊                                                       | 18894/74286 [00:03<00:09, 6108.51it/s]\n",
      " 26%|███████████████████▍                                                      | 19572/74286 [00:03<00:08, 6295.33it/s]\n",
      " 27%|████████████████████▏                                                     | 20204/74286 [00:03<00:08, 6155.06it/s]\n",
      " 28%|████████████████████▊                                                     | 20843/74286 [00:03<00:08, 6223.58it/s]\n",
      " 29%|█████████████████████▍                                                    | 21468/74286 [00:03<00:09, 5830.12it/s]\n",
      " 30%|█████████████████████▉                                                    | 22058/74286 [00:03<00:09, 5722.98it/s]\n",
      " 30%|██████████████████████▌                                                   | 22636/74286 [00:04<00:09, 5630.61it/s]\n",
      " 31%|███████████████████████                                                   | 23203/74286 [00:04<00:09, 5185.51it/s]\n",
      " 32%|███████████████████████▋                                                  | 23732/74286 [00:04<00:10, 5051.83it/s]\n",
      " 33%|████████████████████████▏                                                 | 24258/74286 [00:04<00:09, 5097.47it/s]\n",
      " 33%|████████████████████████▋                                                 | 24812/74286 [00:04<00:09, 5222.43it/s]\n",
      " 34%|█████████████████████████▏                                                | 25339/74286 [00:04<00:09, 5033.82it/s]\n",
      " 35%|█████████████████████████▊                                                | 25955/74286 [00:04<00:09, 5325.75it/s]\n",
      " 36%|██████████████████████████▍                                               | 26514/74286 [00:04<00:08, 5402.17it/s]\n",
      " 36%|██████████████████████████▉                                               | 27060/74286 [00:04<00:08, 5285.31it/s]\n",
      " 37%|███████████████████████████▍                                              | 27600/74286 [00:05<00:08, 5319.10it/s]\n",
      " 38%|████████████████████████████                                              | 28143/74286 [00:05<00:08, 5351.68it/s]\n",
      " 39%|████████████████████████████▌                                             | 28731/74286 [00:05<00:08, 5499.73it/s]\n",
      " 39%|█████████████████████████████▏                                            | 29284/74286 [00:05<00:08, 5249.69it/s]\n",
      " 40%|█████████████████████████████▋                                            | 29864/74286 [00:05<00:08, 5403.31it/s]\n",
      " 41%|██████████████████████████████▎                                           | 30459/74286 [00:05<00:07, 5556.18it/s]\n",
      " 42%|██████████████████████████████▉                                           | 31019/74286 [00:05<00:07, 5431.38it/s]\n",
      " 43%|███████████████████████████████▍                                          | 31602/74286 [00:05<00:07, 5544.91it/s]\n",
      " 43%|████████████████████████████████                                          | 32160/74286 [00:05<00:07, 5409.75it/s]\n",
      " 44%|████████████████████████████████▋                                         | 32789/74286 [00:05<00:07, 5646.55it/s]\n",
      " 45%|█████████████████████████████████▎                                        | 33383/74286 [00:06<00:07, 5731.38it/s]\n",
      " 46%|█████████████████████████████████▉                                        | 34080/74286 [00:06<00:06, 6053.94it/s]\n",
      " 47%|██████████████████████████████████▋                                       | 34788/74286 [00:06<00:06, 6328.89it/s]\n",
      " 48%|███████████████████████████████████▎                                      | 35433/74286 [00:06<00:06, 6364.50it/s]\n",
      " 49%|████████████████████████████████████                                      | 36151/74286 [00:06<00:05, 6588.79it/s]\n",
      " 50%|████████████████████████████████████▋                                     | 36817/74286 [00:06<00:05, 6531.92it/s]\n",
      " 50%|█████████████████████████████████████▎                                    | 37491/74286 [00:06<00:05, 6592.74it/s]\n",
      " 51%|██████████████████████████████████████▌                                    | 38154/74286 [00:11<01:24, 427.73it/s]\n",
      " 52%|██████████████████████████████████████▉                                    | 38622/74286 [00:11<01:00, 587.90it/s]\n",
      " 53%|███████████████████████████████████████▌                                   | 39187/74286 [00:11<00:43, 804.00it/s]\n",
      " 54%|███████████████████████████████████████▌                                  | 39768/74286 [00:11<00:31, 1084.26it/s]\n",
      " 54%|████████████████████████████████████████▏                                 | 40385/74286 [00:12<00:23, 1440.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████▊                                 | 40969/74286 [00:12<00:17, 1861.03it/s]\n",
      " 56%|█████████████████████████████████████████▍                                | 41551/74286 [00:12<00:14, 2338.14it/s]\n",
      " 57%|█████████████████████████████████████████▉                                | 42134/74286 [00:12<00:11, 2850.25it/s]\n",
      " 58%|██████████████████████████████████████████▌                               | 42736/74286 [00:12<00:09, 3384.86it/s]\n",
      " 58%|███████████████████████████████████████████▏                              | 43342/74286 [00:12<00:07, 3897.70it/s]\n",
      " 59%|███████████████████████████████████████████▊                              | 43946/74286 [00:12<00:06, 4356.97it/s]\n",
      " 60%|████████████████████████████████████████████▎                             | 44538/74286 [00:12<00:06, 4588.57it/s]\n",
      " 61%|████████████████████████████████████████████▉                             | 45121/74286 [00:12<00:05, 4901.55it/s]\n",
      " 62%|█████████████████████████████████████████████▌                            | 45757/74286 [00:12<00:05, 5263.49it/s]\n",
      " 63%|██████████████████████████████████████████████▎                           | 46442/74286 [00:13<00:04, 5656.34it/s]\n",
      " 63%|██████████████████████████████████████████████▉                           | 47063/74286 [00:13<00:04, 5747.03it/s]\n",
      " 64%|███████████████████████████████████████████████▌                          | 47740/74286 [00:13<00:04, 6019.72it/s]\n",
      " 65%|████████████████████████████████████████████████▏                         | 48396/74286 [00:13<00:04, 6172.00it/s]\n",
      " 66%|████████████████████████████████████████████████▊                         | 49036/74286 [00:13<00:04, 6211.20it/s]\n",
      " 67%|█████████████████████████████████████████████████▌                        | 49757/74286 [00:13<00:03, 6480.29it/s]\n",
      " 68%|██████████████████████████████████████████████████▏                       | 50420/74286 [00:13<00:03, 6438.70it/s]\n",
      " 69%|██████████████████████████████████████████████████▉                       | 51195/74286 [00:13<00:03, 6773.88it/s]\n",
      " 70%|███████████████████████████████████████████████████▋                      | 51884/74286 [00:13<00:03, 6767.92it/s]\n",
      " 71%|████████████████████████████████████████████████████▎                     | 52569/74286 [00:13<00:03, 6643.84it/s]\n",
      " 72%|█████████████████████████████████████████████████████                     | 53254/74286 [00:14<00:03, 6704.13it/s]\n",
      " 73%|█████████████████████████████████████████████████████▋                    | 53929/74286 [00:14<00:03, 6589.67it/s]\n",
      " 74%|██████████████████████████████████████████████████████▍                   | 54707/74286 [00:14<00:02, 6906.44it/s]\n",
      " 75%|███████████████████████████████████████████████████████▏                  | 55405/74286 [00:14<00:02, 6492.92it/s]\n",
      " 75%|███████████████████████████████████████████████████████▊                  | 56074/74286 [00:14<00:02, 6550.67it/s]\n",
      " 77%|████████████████████████████████████████████████████████▋                 | 56856/74286 [00:14<00:02, 6885.70it/s]\n",
      " 77%|█████████████████████████████████████████████████████████▎                | 57554/74286 [00:14<00:02, 6892.92it/s]\n",
      " 78%|██████████████████████████████████████████████████████████                | 58250/74286 [00:14<00:02, 6882.01it/s]\n",
      " 79%|██████████████████████████████████████████████████████████▋               | 58943/74286 [00:14<00:02, 6824.75it/s]\n",
      " 80%|███████████████████████████████████████████████████████████▍              | 59639/74286 [00:14<00:02, 6864.51it/s]\n",
      " 81%|████████████████████████████████████████████████████████████▏             | 60358/74286 [00:15<00:02, 6958.78it/s]\n",
      " 82%|████████████████████████████████████████████████████████████▊             | 61056/74286 [00:15<00:01, 6852.02it/s]\n",
      " 83%|█████████████████████████████████████████████████████████████▌            | 61758/74286 [00:15<00:01, 6901.31it/s]\n",
      " 84%|██████████████████████████████████████████████████████████████▏           | 62450/74286 [00:15<00:01, 6824.89it/s]\n",
      " 85%|██████████████████████████████████████████████████████████████▉           | 63134/74286 [00:15<00:01, 6829.17it/s]\n",
      " 86%|███████████████████████████████████████████████████████████████▌          | 63832/74286 [00:15<00:01, 6873.47it/s]\n",
      " 87%|████████████████████████████████████████████████████████████████▎         | 64562/74286 [00:15<00:01, 6995.85it/s]\n",
      " 88%|█████████████████████████████████████████████████████████████████         | 65342/74286 [00:15<00:01, 7218.86it/s]\n",
      " 89%|█████████████████████████████████████████████████████████████████▊        | 66067/74286 [00:15<00:01, 7017.97it/s]\n",
      " 90%|██████████████████████████████████████████████████████████████████▌       | 66773/74286 [00:15<00:01, 7030.28it/s]\n",
      " 91%|███████████████████████████████████████████████████████████████████▏      | 67486/74286 [00:16<00:00, 7059.63it/s]\n",
      " 92%|███████████████████████████████████████████████████████████████████▉      | 68194/74286 [00:16<00:00, 7023.39it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████████▋     | 68898/74286 [00:16<00:00, 6955.18it/s]\n",
      " 94%|█████████████████████████████████████████████████████████████████████▎    | 69595/74286 [00:16<00:00, 6938.46it/s]\n",
      " 95%|██████████████████████████████████████████████████████████████████████    | 70290/74286 [00:16<00:00, 6879.91it/s]\n",
      " 96%|██████████████████████████████████████████████████████████████████████▋   | 71003/74286 [00:16<00:00, 6952.82it/s]\n",
      " 97%|███████████████████████████████████████████████████████████████████████▍  | 71699/74286 [00:16<00:00, 6892.72it/s]\n",
      " 98%|████████████████████████████████████████████████████████████████████████▏ | 72451/74286 [00:16<00:00, 7069.27it/s]\n",
      " 98%|████████████████████████████████████████████████████████████████████████▉ | 73160/74286 [00:16<00:00, 6970.95it/s]\n",
      " 99%|█████████████████████████████████████████████████████████████████████████▋| 73912/74286 [00:17<00:00, 7126.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 74286/74286 [00:17<00:00, 4350.15it/s]\n",
      "  0%|                                                                                           | 0/17 [00:00<?, ?it/s]\n",
      "  6%|████▉                                                                              | 1/17 [00:00<00:03,  4.18it/s]\n",
      " 12%|█████████▊                                                                         | 2/17 [00:00<00:03,  4.89it/s]\n",
      " 18%|██████████████▋                                                                    | 3/17 [00:00<00:02,  5.35it/s]\n",
      " 24%|███████████████████▌                                                               | 4/17 [00:00<00:02,  6.11it/s]\n",
      " 29%|████████████████████████▍                                                          | 5/17 [00:00<00:02,  5.55it/s]\n",
      " 35%|█████████████████████████████▎                                                     | 6/17 [00:00<00:01,  6.13it/s]\n",
      " 41%|██████████████████████████████████▏                                                | 7/17 [00:01<00:01,  6.54it/s]\n",
      " 53%|███████████████████████████████████████████▉                                       | 9/17 [00:01<00:01,  6.26it/s]\n",
      " 59%|████████████████████████████████████████████████▏                                 | 10/17 [00:01<00:01,  6.19it/s]\n",
      " 65%|█████████████████████████████████████████████████████                             | 11/17 [00:01<00:00,  6.68it/s]\n",
      " 71%|█████████████████████████████████████████████████████████▉                        | 12/17 [00:01<00:00,  6.86it/s]\n",
      " 76%|██████████████████████████████████████████████████████████████▋                   | 13/17 [00:01<00:00,  7.33it/s]\n",
      " 82%|███████████████████████████████████████████████████████████████████▌              | 14/17 [00:02<00:00,  5.74it/s]\n",
      " 88%|████████████████████████████████████████████████████████████████████████▎         | 15/17 [00:02<00:00,  5.83it/s]\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▏    | 16/17 [00:02<00:00,  6.01it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [00:02<00:00,  4.89it/s]\n"
     ]
    }
   ],
   "source": [
    "dftrain = pos_questions(dftrain)\n",
    "dftest = pos_questions(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbfac1894274cc990eda95a46b48895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99584127476529949, 0.00073714356968668682)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'len_paragraph', 'len_question', \n",
    "           'distance_std',\n",
    "           'question_uppercase_count', 'question_uppercase_part',\n",
    "           'sentence_distance_min',\n",
    "           'levenshtein_to_paragraph', 'levenshtein_sentence_to_question', 'levenshtein_sentence_to_paragraph',\n",
    "           'distance_mean', 'levenshtein_to_question',\n",
    "           'ADJF_count', 'ADJS_count', 'ADVB_count', 'COMP_count',\n",
    "           'CONJ_count', 'GRND_count', 'INFN_count', 'INTJ_count',\n",
    "           'NOUN_count', 'NPRO_count', 'NUMR_count', 'PRCL_count',\n",
    "           'PRED_count', 'PREP_count', 'PRTF_count', 'PRTS_count',\n",
    "           'VERB_count']\n",
    "cv(XGBClassifier(n_estimators=350),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.5, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_columns = ['ADJF_count', 'ADJS_count', 'ADVB_count', 'COMP_count',\n",
    "               'CONJ_count', 'GRND_count', 'INFN_count', 'INTJ_count',\n",
    "               'NOUN_count', 'NPRO_count', 'NUMR_count', 'PRCL_count',\n",
    "               'PRED_count', 'PREP_count', 'PRTF_count', 'PRTS_count',\n",
    "               'VERB_count']\n",
    "svm = OneClassSVM(verbose=True)\n",
    "svm.fit(np.array(dftrain[tag_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftrain['pos_svm'] = svm.predict(np.array(dftrain[tag_columns]))\n",
    "dftest['pos_svm'] = svm.predict(np.array(dftest[tag_columns]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66672fd152440d4bfab74161bb1d4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>IntProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "IntProgress(value=0, max=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.99584215600350512, 0.00072587409555799993)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['sentence_intersection_sizes', 'sentence_intersection_idf',\n",
    "           'sentence_intersection_mean_to_paragraph', 'sentence_intersection_mean_to_question',\n",
    "           'sentence_intersection_std_to_paragraph', 'sentence_intersection_std_to_question',\n",
    "           'idf_question', 'idf_paragraph', 'idf_intersection',\n",
    "           'len_paragraph', 'len_question', \n",
    "           'distance_std',\n",
    "           'question_uppercase_count', 'question_uppercase_part',\n",
    "           'sentence_distance_min',\n",
    "           'levenshtein_to_paragraph', 'levenshtein_sentence_to_question', 'levenshtein_sentence_to_paragraph',\n",
    "           'distance_mean', 'levenshtein_to_question',\n",
    "           'ADJF_count', 'ADJS_count', 'ADVB_count', 'COMP_count',\n",
    "           'CONJ_count', 'GRND_count', 'INFN_count', 'INTJ_count',\n",
    "           'NOUN_count', 'NPRO_count', 'NUMR_count', 'PRCL_count',\n",
    "           'PRED_count', 'PREP_count', 'PRTF_count', 'PRTS_count',\n",
    "           'VERB_count', \n",
    "           'pos_svm']\n",
    "cv(XGBClassifier(n_estimators=350),\n",
    "   np.array(dftrain[columns]),\n",
    "   np.array(dftrain['target']),\n",
    "   dftrain[\"question_id\"],\n",
    "   dftrain[\"paragraph_id\"],\n",
    "   1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(n_estimators=350).fit(np.array(dftrain[columns]), np.array(dftrain['target']))\n",
    "dftest[\"prediction\"] = classifier.predict_proba(np.array(dftest[columns]))[:, 1]\n",
    "dftest[['paragraph_id', 'question_id', 'prediction']].to_csv('../output/prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
