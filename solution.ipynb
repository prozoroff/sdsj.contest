{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from collections import Counter\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>question</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1094</td>\n",
       "      <td>46273</td>\n",
       "      <td>В отличие от рыб, земноводные (амфибии) и прес...</td>\n",
       "      <td>С какого года Русское Царство перешло на летои...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7414</td>\n",
       "      <td>19164</td>\n",
       "      <td>В 1049 году Балдуину V удалось отнять у Герман...</td>\n",
       "      <td>Кто упомянул о его первых разногласиях со Штей...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6744</td>\n",
       "      <td>39767</td>\n",
       "      <td>Стремление достичь предельных значений ёмкости...</td>\n",
       "      <td>Как называется имеющая мировое значение эпоха ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7300</td>\n",
       "      <td>36318</td>\n",
       "      <td>Первый практически пригодный двухтактный газов...</td>\n",
       "      <td>Что усугублялось из-за международного давления...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7077</td>\n",
       "      <td>41534</td>\n",
       "      <td>Требуя от художника углубленного изучения изоб...</td>\n",
       "      <td>Какой характер носят пророчества Леонардо да В...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paragraph_id  question_id  \\\n",
       "0          1094        46273   \n",
       "1          7414        19164   \n",
       "2          6744        39767   \n",
       "3          7300        36318   \n",
       "4          7077        41534   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  В отличие от рыб, земноводные (амфибии) и прес...   \n",
       "1  В 1049 году Балдуину V удалось отнять у Герман...   \n",
       "2  Стремление достичь предельных значений ёмкости...   \n",
       "3  Первый практически пригодный двухтактный газов...   \n",
       "4  Требуя от художника углубленного изучения изоб...   \n",
       "\n",
       "                                            question  target  \n",
       "0  С какого года Русское Царство перешло на летои...     0.0  \n",
       "1  Кто упомянул о его первых разногласиях со Штей...     0.0  \n",
       "2  Как называется имеющая мировое значение эпоха ...     0.0  \n",
       "3  Что усугублялось из-за международного давления...     0.0  \n",
       "4  Какой характер носят пророчества Леонардо да В...     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain = pd.read_csv(\"train_task1_latest.csv\", encoding='utf-8')[:1000]\n",
    "dftest = pd.read_csv(\"sdsj_A_test.csv\", encoding='utf-8')\n",
    "\n",
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['paragraph_id', 'question_id', 'paragraph', 'question'];\n",
    "\n",
    "stemer = RussianStemmer()\n",
    "regex = re.compile('[^а-яА-Я ]')\n",
    "stem_cache = {}\n",
    "\n",
    "def get_stem(token):\n",
    "    stem = stem_cache.get(token, None)\n",
    "    if stem:\n",
    "        return stem\n",
    "    token = regex.sub('', token).lower()\n",
    "    stem = stemer.stem(token)\n",
    "    stem_cache[token] = stem\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_count = Counter()\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def count_unique_tokens(texts):\n",
    "    for text in texts:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        for token in tokens:\n",
    "            stem = get_stem(token)\n",
    "            stem_count[stem] += 1\n",
    "\n",
    "count_unique_tokens(dftrain.paragraph)\n",
    "count_unique_tokens(dftrain.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique stems found:  10513\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique stems found: \", len(stem_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'в', 'и', 'с', 'на', 'год', 'как', 'был', 'котор', 'по', 'к', 'эт', 'для', 'не', 'из', 'от', 'ил', 'что', 'а', 'сво', 'друг', 'он', 'при', 'так', 'ег', 'за', 'такж', 'но', 'у', 'част', 'врем', 'то', 'одн', 'о', 'е', 'вид', 'перв', 'явля', 'во', 'их', 'же', 'до', 'может', 'нов', 'бол', 'образ', 'посл', 'межд', 'например', 'век', 'больш', 'форм', 'втор', 'банк', 'называ', 'сам', 'течен', 'прав', 'под', 'действ', 'быт', 'когд', 'чем', 'том', 'разум', 'мног', 'стал', 'со', 'времен', 'систем', 'мир', 'сем', 'отношен', 'человек', 'нескольк', 'все', 'ещ', 'тог', 'могут', 'тольк', 'некотор', 'ива', 'фильм', 'организм', 'лет', 'уж', 'ряд', 'двигател', 'через', 'сын', 'об', 'язык', 'территор', 'использова', 'опер', 'писател', 'развит', 'город', 'французск', 'возможн']\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "vocab = sorted(stem_count, key=stem_count.get, reverse=True)[:VOCAB_SIZE]\n",
    "print(vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_2_idx = {vocab[i] : i for i in range(VOCAB_SIZE)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_vector(text, show_unknowns=False):\n",
    "    vector = np.zeros(VOCAB_SIZE, dtype=np.int_)\n",
    "    for token in tokenizer.tokenize(text):\n",
    "        stem = get_stem(token)\n",
    "        idx = token_2_idx.get(stem, None)\n",
    "        if idx is not None:\n",
    "            vector[idx] = 1\n",
    "        elif show_unknowns:\n",
    "            print(\"Unknown token: {}\".format(token))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: В отличие от рыб, земноводные (амфибии) и пресмыкающиеся (рептилии или гады) уже имеют два круга кровообращения и сердце у них трёхкамерное (появляется межпредсердная перегородка). Единственные современные рептилии, имеющие хотя и неполноценное (межпредсердиевая перегородка не полностью разделяет предсердия, что скорей всего связано с переходом предков к полуводному образу жизни и снижению активности), но уже четырёхкамерное сердце — крокодилы. Считается, что впервые четырёхкамерное сердце появилось у примитивных архозавров и развитых синапсидов. В дальнейшем такое строение сердца унаследовали прямые потомки динозавров — птицы и потомки примитивных млекопитающих — современные млекопитающие.\n",
      "vector: [1 1 1 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text = dftrain.paragraph[0]\n",
    "print(\"text: {}\".format(text))\n",
    "print(\"vector: {}\".format(text_to_vector(text)[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectors = np.zeros(\n",
    "    (len(dftrain.paragraph), VOCAB_SIZE*2), \n",
    "    dtype=np.int_)\n",
    "\n",
    "for ind in range(len(dftrain.paragraph)):\n",
    "    text_vectors[ind][:VOCAB_SIZE] = text_to_vector(dftrain.paragraph[ind])\n",
    "    \n",
    "for ind in range(len(dftrain.question)):\n",
    "    text_vectors[ind][VOCAB_SIZE:] = text_to_vector(dftrain.question[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dftrain.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = text_vectors\n",
    "y = to_categorical(labels, 2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(learning_rate=0.1):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    net = tflearn.input_data([None, VOCAB_SIZE*2])\n",
    "    net = tflearn.fully_connected(net, 125, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 25, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "    regression = tflearn.regression(\n",
    "        net, \n",
    "        optimizer='sgd', \n",
    "        learning_rate=learning_rate, \n",
    "        loss='categorical_crossentropy')\n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model(learning_rate=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.37683\u001b[0m\u001b[0m | time: 0.118s\n",
      "| SGD | epoch: 033 | loss: 0.37683 - acc: 0.9100 -- iter: 512/630\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.35898\u001b[0m\u001b[0m | time: 1.160s\n",
      "| SGD | epoch: 033 | loss: 0.35898 - acc: 0.9165 | val_loss: 0.37102 - val_acc: 0.8000 -- iter: 630/630\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    validation_set=0.1, \n",
    "    show_metric=True, \n",
    "    batch_size=128, \n",
    "    n_epoch=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = (np.array(model.predict(X_test))[:,0] >= 0.5).astype(np.int_)\n",
    "accuracy = np.mean(predictions == y_test[:,0], axis=0)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
